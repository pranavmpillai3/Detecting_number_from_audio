{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qMl262OaS-x3",
    "jupyter": {
     "source_hidden": true
    },
    "outputId": "c021c833-a42f-41a6-bafc-959b57ff87ce",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "gEMRYr7LTMUh",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/pranav/AIML/AI/CV/MyProjects/Detecting_NO_from_Audio'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "pgCUwe09TMXg",
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# os.environ['KAGGLE_CONFIG_DIR'] = '/content/drive/MyDrive/kaggle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "VqV84DMpTMaI",
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Ql4MDN5ZTMdA",
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# os.chdir('/content/drive/MyDrive/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "vUmGHhUFTMfw",
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !kaggle datasets download -d sripaadsrinivasan/audio-mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "QJ4RCMerTMiY",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Detecting_phno_from_voice-20231013T045341Z-001.zip',\n",
       " 'Detecting_PhoneNo_from_live_audio.ipynb',\n",
       " 'Detecting_phno_from_voice',\n",
       " '.ipynb_checkpoints']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "2NaRYPz1j4Ft",
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.makedirs(f'/content/drive/MyDrive/gdrive/Detecting_phno_from_voice',exist_ok=True)\n",
    "# os.makedirs(f'/content/drive/MyDrive/gdrive/voice_data',exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "6SGEdE_iTMoD",
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# zip_path = '/content/drive/MyDrive/gdrive/audio-mnist.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "7N-SnNuKTMq6",
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !cp {'zip_path'  '/content/drive/MyDrive/gdrive/voice_data'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "D7aTvA0ETMto",
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !unzip -q 'audio-mnist.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "caJK0tS5TMxA",
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.chdir('/content/drive/MyDrive/gdrive/Detecting_phno_from_voice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "xPcnBIl0TnRt",
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# voicedata = os.listdir('/content/drive/MyDrive/gdrive/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "voicedata = os.listdir('/Users/pranav/AIML/AI/CV/MyProjects/Detecting_NO_from_Audio/Detecting_phno_from_voice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cU-rZggVTnUY",
    "outputId": "95047150-4572-4e8e-c2d3-f23765af6617",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['9', '0', '7', '6', '1', '8', '4', '3', '2', '5']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voicedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "d4-frvxmY_YP",
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# voicedata.remove('audioMNIST_meta.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "xsEi8WDMTnXZ",
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for i in range(0,10):\n",
    "#   os.makedirs(os.path.join('/content/drive/MyDrive/gdrive/Detecting_phno_from_voice/',f'{i}'),exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "_cLxtRaQgVe2",
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import shutil\n",
    "\n",
    "# for dir in voicedata:\n",
    "#   for i in range(0, 10):\n",
    "#     for j in range(0, 50):\n",
    "#       src_path = os.path.join('/content/drive/MyDrive/gdrive/data', dir,f'{i}_{dir}_{j}.wav')\n",
    "#       # print(src_path)\n",
    "#       dst_path = os.path.join(f'/content/drive/MyDrive/gdrive/Detecting_phno_from_voice/', str(i))\n",
    "#       # print(dst_path)\n",
    "#       shutil.copy(src_path, dst_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ghg2SxpXa_Tw",
    "outputId": "af655be6-d078-4a85-a48c-de95a0db8363",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files in /Users/pranav/AIML/AI/CV/MyProjects/Detecting_NO_from_Audio/Detecting_phno_from_voice/: 30000\n"
     ]
    }
   ],
   "source": [
    "def count_files_in_directory(path):\n",
    "    total_files = 0\n",
    "\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        total_files += len(files)\n",
    "\n",
    "    return total_files\n",
    "\n",
    "# Example usage:\n",
    "directory_path = '/Users/pranav/AIML/AI/CV/MyProjects/Detecting_NO_from_Audio/Detecting_phno_from_voice/'\n",
    "total_files = count_files_in_directory(directory_path)\n",
    "print(f\"Total files in {directory_path}: {total_files}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KarcFNiW56Gd",
    "jupyter": {
     "source_hidden": true
    },
    "outputId": "686e5bdf-7b95-424d-b6e3-26373746737b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install --upgrade tensorflow-io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ofux1oZ17HQL",
    "outputId": "2cbc6c0a-ac23-4094-bff0-5642810382e8",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.34.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pranav/anaconda3/envs/myenv/lib/python3.11/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/Users/pranav/anaconda3/envs/myenv/lib/python3.11/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: [\"[Errno 2] The file to load file system plugin from does not exist.: '/Users/pranav/anaconda3/envs/myenv/lib/python3.11/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so'\"]\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/Users/pranav/anaconda3/envs/myenv/lib/python3.11/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/Users/pranav/anaconda3/envs/myenv/lib/python3.11/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: [\"dlopen(/Users/pranav/anaconda3/envs/myenv/lib/python3.11/site-packages/tensorflow_io/python/ops/libtensorflow_io.so, 0x0006): tried: '/Users/pranav/anaconda3/envs/myenv/lib/python3.11/site-packages/tensorflow_io/python/ops/libtensorflow_io.so' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/Users/pranav/anaconda3/envs/myenv/lib/python3.11/site-packages/tensorflow_io/python/ops/libtensorflow_io.so' (no such file), '/Users/pranav/anaconda3/envs/myenv/lib/python3.11/site-packages/tensorflow_io/python/ops/libtensorflow_io.so' (no such file)\"]\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_io as tfio\n",
    "print(tfio.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "l-EMicnna_WV",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "DqyL0y2pijsq",
    "tags": []
   },
   "outputs": [],
   "source": [
    "number_list = []\n",
    "for i in range(0, 10):\n",
    "  number_list.append(os.path.join(directory_path, f'{i}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9mVsKDpyjmVg",
    "outputId": "7dcb9767-9ad6-4873-95ba-c0e6a325b292",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/pranav/AIML/AI/CV/MyProjects/Detecting_NO_from_Audio/Detecting_phno_from_voice/0',\n",
       " '/Users/pranav/AIML/AI/CV/MyProjects/Detecting_NO_from_Audio/Detecting_phno_from_voice/1',\n",
       " '/Users/pranav/AIML/AI/CV/MyProjects/Detecting_NO_from_Audio/Detecting_phno_from_voice/2',\n",
       " '/Users/pranav/AIML/AI/CV/MyProjects/Detecting_NO_from_Audio/Detecting_phno_from_voice/3',\n",
       " '/Users/pranav/AIML/AI/CV/MyProjects/Detecting_NO_from_Audio/Detecting_phno_from_voice/4',\n",
       " '/Users/pranav/AIML/AI/CV/MyProjects/Detecting_NO_from_Audio/Detecting_phno_from_voice/5',\n",
       " '/Users/pranav/AIML/AI/CV/MyProjects/Detecting_NO_from_Audio/Detecting_phno_from_voice/6',\n",
       " '/Users/pranav/AIML/AI/CV/MyProjects/Detecting_NO_from_Audio/Detecting_phno_from_voice/7',\n",
       " '/Users/pranav/AIML/AI/CV/MyProjects/Detecting_NO_from_Audio/Detecting_phno_from_voice/8',\n",
       " '/Users/pranav/AIML/AI/CV/MyProjects/Detecting_NO_from_Audio/Detecting_phno_from_voice/9']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "c5o09Ith1ABw",
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# one = number_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "4gddowPK1AEY",
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "N2sJ33dN1AHg",
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# one_train = tf.data.Dataset.list_files(one+'/*.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "iBRlIAFbzx42",
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# one_train = tf.data.Dataset.zip((one_train, tf.data.Dataset.from_tensor_slices(tf.ones(len(one_train)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# len(one_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_list = []\n",
    "for i in range(0, 10):\n",
    "  dataset_list.append(tf.data.Dataset.list_files(number_list[i]+'/*.wav'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<_ShuffleDataset element_spec=TensorSpec(shape=(), dtype=tf.string, name=None)>,\n",
       " <_ShuffleDataset element_spec=TensorSpec(shape=(), dtype=tf.string, name=None)>,\n",
       " <_ShuffleDataset element_spec=TensorSpec(shape=(), dtype=tf.string, name=None)>,\n",
       " <_ShuffleDataset element_spec=TensorSpec(shape=(), dtype=tf.string, name=None)>,\n",
       " <_ShuffleDataset element_spec=TensorSpec(shape=(), dtype=tf.string, name=None)>,\n",
       " <_ShuffleDataset element_spec=TensorSpec(shape=(), dtype=tf.string, name=None)>,\n",
       " <_ShuffleDataset element_spec=TensorSpec(shape=(), dtype=tf.string, name=None)>,\n",
       " <_ShuffleDataset element_spec=TensorSpec(shape=(), dtype=tf.string, name=None)>,\n",
       " <_ShuffleDataset element_spec=TensorSpec(shape=(), dtype=tf.string, name=None)>,\n",
       " <_ShuffleDataset element_spec=TensorSpec(shape=(), dtype=tf.string, name=None)>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dataset = []\n",
    "# for i in range(10):\n",
    "#     dataset_i = dataset_list[i]\n",
    "#     length_tensor = len(dataset_i)\n",
    "\n",
    "#     def generator():\n",
    "#         for item in dataset_i:\n",
    "#             yield (item, length_tensor)\n",
    "\n",
    "#     length_dataset = tf.data.Dataset.from_generator(generator, (tf.float32, tf.int32), (tf.TensorShape([]), tf.TensorShape([])))\n",
    "\n",
    "#     dataset.append(length_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = []\n",
    "for i in range(0, 10):\n",
    "    labels = tf.fill(dims=len(dataset_list[i]), value=i)\n",
    "    dataset.append(tf.data.Dataset.zip(dataset_list[i], tf.data.Dataset.from_tensor_slices(labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<_ZipDataset element_spec=(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(), dtype=tf.int32, name=None))>,\n",
       " <_ZipDataset element_spec=(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(), dtype=tf.int32, name=None))>,\n",
       " <_ZipDataset element_spec=(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(), dtype=tf.int32, name=None))>,\n",
       " <_ZipDataset element_spec=(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(), dtype=tf.int32, name=None))>,\n",
       " <_ZipDataset element_spec=(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(), dtype=tf.int32, name=None))>,\n",
       " <_ZipDataset element_spec=(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(), dtype=tf.int32, name=None))>,\n",
       " <_ZipDataset element_spec=(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(), dtype=tf.int32, name=None))>,\n",
       " <_ZipDataset element_spec=(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(), dtype=tf.int32, name=None))>,\n",
       " <_ZipDataset element_spec=(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(), dtype=tf.int32, name=None))>,\n",
       " <_ZipDataset element_spec=(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(), dtype=tf.int32, name=None))>]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = None\n",
    "for ds in dataset:\n",
    "  if data is None:\n",
    "    data = ds\n",
    "  else:\n",
    "    data = data.concatenate(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_ConcatenateDataset element_spec=(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(), dtype=tf.int32, name=None))>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_wav_16k_mono(filename):\n",
    "    file_contents = tf.io.read_file(filename)\n",
    "    wav, sample_rate = tf.audio.decode_wav(file_contents, desired_channels=1)\n",
    "    wav = tf.squeeze(wav, axis=-1)\n",
    "    sample_rate = tf.cast(sample_rate, dtype=tf.int64)\n",
    "    # wav = tfio.audio.resample(wav, rate_in=sample_rate, rate_out=16000)\n",
    "    return wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# file_contents = tf.io.read_file('/Users/pranav/AIML/AI/CV/MyProjects/Detecting_NO_from_Audio/Detecting_phno_from_voice/0/0_01_0.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# wav, sample_rate = tf.audio.decode_wav(file_contents, desired_channels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sample_rate = tf.cast(sample_rate, dtype=tf.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# wav = tf.squeeze(wav, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# wav = tfio.audio.resample(wav, rate_in=sample_rate, rate_out=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lengths = []\n",
    "all_lengths = []\n",
    "for i in range(0, 10):\n",
    "    for files in os.listdir(os.path.join('/Users/pranav/AIML/AI/CV/MyProjects/Detecting_NO_from_Audio/Detecting_phno_from_voice/', str(i))):\n",
    "        tensor_wave = load_wav_16k_mono(os.path.join(f'/Users/pranav/AIML/AI/CV/MyProjects/Detecting_NO_from_Audio/Detecting_phno_from_voice/{str(i)}', str(files)))\n",
    "        lengths.append(len(tensor_wave))\n",
    "    all_lengths.append(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=30844>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.reduce_mean(all_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=14073>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.reduce_min(all_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=47998>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.reduce_max(all_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess(file_path, label):\n",
    "    wav = load_wav_16k_mono(file_path)\n",
    "    wav = wav[:30000]\n",
    "    zero_padding = tf.zeros([30000] - tf.shape(wav), dtype=tf.float32)\n",
    "    wav = tf.concat([zero_padding, wav],0)\n",
    "    spectrogram = tf.signal.stft(wav, frame_length=80, frame_step=40)\n",
    "    spectrogram = tf.abs(spectrogram)\n",
    "    spectrogram = tf.expand_dims(spectrogram, axis=2)\n",
    "    return spectrogram, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(features, labels):\n",
    "    labels_one_hot = tf.one_hot(labels, depth=10)\n",
    "    return features, labels_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = data.map(preprocess)\n",
    "train_data = train_data.map(one_hot_encode)\n",
    "train_data = train_data.cache()\n",
    "train_data = train_data.shuffle(buffer_size=10000)\n",
    "train_data = train_data.batch(8)\n",
    "train_data = train_data.prefetch(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, None, 65, 1), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "750.0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)*.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = train_data.take(3000)\n",
    "val = train_data.skip(3000).take(750)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_TakeDataset element_spec=(TensorSpec(shape=(None, None, 65, 1), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-20 10:19:13.199939: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "samples, labels = train.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 749, 65, 1)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(16, (3,3), activation='relu', input_shape=(749, 65, 1)))\n",
    "model.add(Conv2D(16, (3,3), activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile('Adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 747, 63, 16)       160       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 745, 61, 16)       2320      \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 727120)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               93071488  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 93075258 (355.05 MB)\n",
      "Trainable params: 93075258 (355.05 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "3000/3000 [==============================] - 763s 253ms/step - loss: 0.2470 - accuracy: 0.9339 - val_loss: 0.0807 - val_accuracy: 0.9797\n",
      "Epoch 2/2\n",
      "3000/3000 [==============================] - 715s 238ms/step - loss: 0.0860 - accuracy: 0.9747 - val_loss: 0.1464 - val_accuracy: 0.9533\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(train, epochs=2, validation_data=val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pranav/anaconda3/envs/myenv/lib/python3.11/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('audionodetect.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
